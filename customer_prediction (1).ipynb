{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO9ykF1UMErc",
        "outputId": "35549f2c-7c30-4330-8607-bb20f659177d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lime in /usr/local/lib/python3.12/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from lime) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lime) (1.16.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from lime) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.12/dist-packages (from lime) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.12/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (2025.10.16)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.18->lime) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.18->lime) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
            "Features detected: ['id', 'fea_1', 'fea_2', 'fea_3', 'fea_4', 'fea_5', 'fea_6', 'fea_7', 'fea_8', 'fea_9', 'fea_10', 'fea_11']\n",
            "Train size: (843, 12) Test size: (282, 12)\n",
            "Starting hyperparameter search\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "Best params: {'colsample_bytree': np.float64(0.7098887171960256), 'learning_rate': np.float64(0.12224868516954022), 'max_depth': 5, 'n_estimators': 200, 'subsample': np.float64(0.9886848381556415)}\n",
            "Best CV AUC: 0.6213972226410036\n",
            "CV AUC scores on train folds: [0.6400871459694989, 0.6553376906318082, 0.6056644880174292, 0.6507901668129938, 0.5551066217732884]\n",
            "Test metrics: {'accuracy': 0.7659574468085106, 'roc_auc': 0.5099557522123894, 'precision': 0.2222222222222222, 'recall': 0.07142857142857142}\n",
            "Selected case indices for local explanations: [30, 482, 352, 142, 276]\n",
            "All outputs saved to output\n",
            "Contents: ['xgb_feature_importance.png', 'case_5_shap_force.txt', 'case_2_shap_contributions.csv', 'case_1_shap_contributions.csv', 'case_2_lime.html', 'comparative_shap_vs_lime.txt', 'global_feature_importance.csv', 'xgb_model.joblib', 'case_1_lime.html', 'local_explanations_summary.json', 'case_3_lime.html', 'case_3_shap_force.txt', 'case_2_shap_force.txt', 'case_4_shap_contributions.csv', 'cv_train_folds.json', 'test_metrics.json', 'case_5_lime.html', 'case_4_transcription.txt', 'case_1_transcription.txt', 'case_4_shap_force.txt', 'case_1_shap_force.txt', 'tuning_results.json', 'deliverables_mapping.txt', 'case_5_transcription.txt', 'case_3_shap_contributions.csv', 'case_3_transcription.txt', 'executive_summary.txt', 'test_classification.json', 'shap_summary.png', 'case_2_transcription.txt', 'case_4_lime.html', 'case_5_shap_contributions.csv']\n",
            "Script finished at 2025-11-19T03:45:30.090717\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, cross_val_score\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "from xgboost import XGBClassifier\n",
        "import shap\n",
        "import joblib\n",
        "from scipy.stats import randint, uniform\n",
        "!pip install lime\n",
        "from lime.lime_tabular import LimeTabularExplainer\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "np.random.seed(42)\n",
        "\n",
        "# ===========\n",
        "# Configuration\n",
        "# ===========\n",
        "DATA_FILE = \"credit_risk.csv\"   # Input dataset filename\n",
        "TARGET_COL = \"label\"               # 0 = accepted, 1 = rejected  <-- Corrected: Changed from \"id\" to \"label\"\n",
        "OUTPUT_DIR = \"output\"\n",
        "N_JOBS = 4\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# ===========\n",
        "# Helpers\n",
        "# ===========\n",
        "def save_json(obj, path):\n",
        "    with open(path, \"w\") as f:\n",
        "        json.dump(obj, f, indent=2)\n",
        "\n",
        "def save_text(text, path):\n",
        "    with open(path, \"w\", encoding=\"utf8\") as f:\n",
        "        f.write(text)\n",
        "\n",
        "def plot_and_save_feature_importance(features, importances, outpath):\n",
        "    order = np.argsort(importances)\n",
        "    plt.figure(figsize=(8, max(4, 0.4 * len(features))))\n",
        "    plt.barh(np.array(features)[order], importances[order])\n",
        "    plt.title(\"XGBoost feature importances\")\n",
        "    plt.xlabel(\"Importance\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(outpath)\n",
        "    plt.close()\n",
        "\n",
        "def safe_shap_summary_plot(explainer, shap_values, X, outpath):\n",
        "    # shap.summary_plot creates its own matplotlib figure\n",
        "    shap.summary_plot(shap_values, X, show=False)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(outpath, bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "def safe_shap_force_plot(explainer, shap_values, X_row, outpath):\n",
        "    # For a single instance produce a force plot and save as PNG using matplotlib\n",
        "    # Use shap.plots._force.matplotlib_force_plot for matplotlib rendering\n",
        "    try:\n",
        "        fp = shap.plots._force.matplotlib_force_plot(explainer.expected_value, shap_values, X_row, show=False)\n",
        "        plt.savefig(outpath, bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "    except Exception as e:\n",
        "        # fallback: save a small text summary\n",
        "        with open(outpath.replace(\".png\", \".txt\"), \"w\") as f:\n",
        "            f.write(\"Could not render force plot: \" + str(e))\n",
        "\n",
        "# ===========\n",
        "# 1. Load data\n",
        "# ===========\n",
        "data=pd.read_csv(\"/content/customer_data.csv\",encoding='latin-1')\n",
        "df = pd.DataFrame(data)\n",
        "if TARGET_COL not in df.columns:\n",
        "    raise ValueError(f\"Target column '{TARGET_COL}' not found in dataset. Columns found: {list(df.columns)}\")\n",
        "\n",
        "# Basic check and feature list\n",
        "feature_cols = [c for c in df.columns if c != TARGET_COL]\n",
        "print(\"Features detected:\", feature_cols)\n",
        "\n",
        "# ===========\n",
        "# 2. Preprocessing\n",
        "#    - simple: numeric fill with median, categorical label encoding if any\n",
        "#    - keep pipeline simple so reviewer can reproduce\n",
        "# ===========\n",
        "X = df[feature_cols].copy()\n",
        "y = df[TARGET_COL].copy()\n",
        "\n",
        "# Auto-detect numeric vs categorical\n",
        "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "cat_cols = [c for c in X.columns if c not in numeric_cols]\n",
        "\n",
        "# Fill numeric missing with median\n",
        "for c in numeric_cols:\n",
        "    if X[c].isnull().any():\n",
        "        X[c] = X[c].fillna(X[c].median())\n",
        "\n",
        "# For categorical columns simple factorize\n",
        "for c in cat_cols:\n",
        "    if X[c].isnull().any():\n",
        "        X[c] = X[c].fillna(\"MISSING\")\n",
        "    X[c], _ = pd.factorize(X[c])\n",
        "\n",
        "# Final feature list\n",
        "features = X.columns.tolist()\n",
        "\n",
        "# ===========\n",
        "# 3. Train test split\n",
        "# ===========\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, stratify=y, random_state=42\n",
        ")\n",
        "print(\"Train size:\", X_train.shape, \"Test size:\", X_test.shape)\n",
        "\n",
        "# ===========\n",
        "# 4. Baseline XGBoost and hyperparameter tuning\n",
        "#    - RandomizedSearchCV with small search to keep runtime reasonable\n",
        "# ===========\n",
        "base_model = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric=\"logloss\",\n",
        "    random_state=42,\n",
        "    n_jobs=N_JOBS\n",
        ")\n",
        "\n",
        "param_dist = {\n",
        "    \"max_depth\": randint(3, 8),\n",
        "    \"learning_rate\": uniform(0.01, 0.2),\n",
        "    \"subsample\": uniform(0.6, 0.4),\n",
        "    \"colsample_bytree\": uniform(0.6, 0.4),\n",
        "    \"n_estimators\": randint(100, 400)\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "search = RandomizedSearchCV(\n",
        "    estimator=base_model,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20,\n",
        "    scoring=\"roc_auc\",\n",
        "    cv=cv,\n",
        "    random_state=42,\n",
        "    n_jobs=N_JOBS,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Starting hyperparameter search\")\n",
        "search.fit(X_train, y_train)\n",
        "best_model = search.best_estimator_\n",
        "print(\"Best params:\", search.best_params_)\n",
        "print(\"Best CV AUC:\", search.best_score_)\n",
        "\n",
        "# Save search results\n",
        "save_json({\n",
        "    \"best_params\": search.best_params_,\n",
        "    \"best_score_cv_auc\": float(search.best_score_)\n",
        "}, os.path.join(OUTPUT_DIR, \"tuning_results.json\"))\n",
        "\n",
        "# ===========\n",
        "# 5. Cross validation on full training set with best model\n",
        "# ===========\n",
        "cv_scores = cross_val_score(best_model, X_train, y_train, cv=cv, scoring=\"roc_auc\", n_jobs=N_JOBS)\n",
        "cv_scores_list = [float(s) for s in cv_scores]\n",
        "print(\"CV AUC scores on train folds:\", cv_scores_list)\n",
        "save_json({\"cv_auc_train_folds\": cv_scores_list}, os.path.join(OUTPUT_DIR, \"cv_train_folds.json\"))\n",
        "\n",
        "# ===========\n",
        "# 6. Final fit on full training set and evaluate on test set\n",
        "# ===========\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "metrics = {\n",
        "    \"accuracy\": float(accuracy_score(y_test, y_pred)),\n",
        "    \"roc_auc\": float(roc_auc_score(y_test, y_proba)),\n",
        "    \"precision\": float(precision_score(y_test, y_pred, zero_division=0)),\n",
        "    \"recall\": float(recall_score(y_test, y_pred, zero_division=0))\n",
        "}\n",
        "print(\"Test metrics:\", metrics)\n",
        "save_json(metrics, os.path.join(OUTPUT_DIR, \"test_metrics.json\"))\n",
        "\n",
        "# Confusion matrix and classification report\n",
        "cm = confusion_matrix(y_test, y_pred).tolist()\n",
        "cr = classification_report(y_test, y_pred, zero_division=0, output_dict=True)\n",
        "save_json({\"confusion_matrix\": cm, \"classification_report\": cr}, os.path.join(OUTPUT_DIR, \"test_classification.json\"))\n",
        "\n",
        "# Save trained model\n",
        "joblib.dump(best_model, os.path.join(OUTPUT_DIR, \"xgb_model.joblib\"))\n",
        "\n",
        "# ===========\n",
        "# 7. Global feature importance and SHAP\n",
        "# ===========\n",
        "# XGBoost feature importances\n",
        "importances = best_model.feature_importances_\n",
        "plot_and_save_feature_importance(features, importances, os.path.join(OUTPUT_DIR, \"xgb_feature_importance.png\"))\n",
        "\n",
        "# SHAP tree explainer\n",
        "explainer = shap.TreeExplainer(best_model)\n",
        "shap_values = explainer.shap_values(X_train)  # shape: (n_samples, n_features) or list for multioutput\n",
        "\n",
        "# Save SHAP summary plot\n",
        "safe_shap_summary_plot(explainer, shap_values, X_train, os.path.join(OUTPUT_DIR, \"shap_summary.png\"))\n",
        "\n",
        "# Save global feature importance numeric values\n",
        "global_shap_importance = pd.DataFrame({\n",
        "    \"feature\": features,\n",
        "    \"xgb_importance\": importances,\n",
        "    \"mean_abs_shap\": np.abs(shap_values).mean(axis=0).tolist() if shap_values is not None and hasattr(shap_values, \"shape\") else []\n",
        "})\n",
        "global_shap_importance = global_shap_importance.sort_values(\"mean_abs_shap\", ascending=False)\n",
        "global_shap_importance.to_csv(os.path.join(OUTPUT_DIR, \"global_feature_importance.csv\"), index=False)\n",
        "\n",
        "# ===========\n",
        "# 8. Select 5 representative loan applications: 3 accepted, 2 rejected\n",
        "#    - If not enough in test set, pick from whole dataset but prefer test set for honest evaluation\n",
        "# ===========\n",
        "selected_indices = []\n",
        "accepted_mask = (y_test == 0)\n",
        "rejected_mask = (y_test == 1)\n",
        "\n",
        "if accepted_mask.sum() >= 3 and rejected_mask.sum() >= 2:\n",
        "    accepted_idx = list(X_test[accepted_mask].index[:3])\n",
        "    rejected_idx = list(X_test[rejected_mask].index[:2])\n",
        "else:\n",
        "    # fallback to using whole data\n",
        "    accepted_idx = list(X[y == 0].index[:3])\n",
        "    rejected_idx = list(X[y == 1].index[:2])\n",
        "\n",
        "selected_indices = accepted_idx + rejected_idx\n",
        "print(\"Selected case indices for local explanations:\", selected_indices)\n",
        "\n",
        "# ===========\n",
        "# 9. Local explanations with SHAP and LIME for each selected case\n",
        "# ===========\n",
        "lime_explainer = LimeTabularExplainer(\n",
        "    training_data=np.array(X_train),\n",
        "    feature_names=features,\n",
        "    class_names=[\"accepted\", \"rejected\"],\n",
        "    discretize_continuous=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "local_summaries = []\n",
        "for i, idx in enumerate(selected_indices):\n",
        "    row = X.loc[idx]\n",
        "    row_df = row.to_frame().T\n",
        "    proba = best_model.predict_proba(row_df)[:, 1][0]\n",
        "    pred = int(best_model.predict(row_df)[0])\n",
        "    shap_val = explainer.shap_values(row_df).reshape(-1) if hasattr(explainer.shap_values(row_df), \"reshape\") else explainer.shap_values(row_df)\n",
        "    # SHAP local contribution table\n",
        "    shap_contrib_df = pd.DataFrame({\n",
        "        \"feature\": features,\n",
        "        \"shap_value\": shap_val if isinstance(shap_val, (list, np.ndarray)) else np.array(shap_val).reshape(-1),\n",
        "        \"value\": row.values\n",
        "    }).sort_values(\"shap_value\", key=lambda s: np.abs(s), ascending=False)\n",
        "    shap_contrib_df.to_csv(os.path.join(OUTPUT_DIR, f\"case_{i+1}_shap_contributions.csv\"), index=False)\n",
        "\n",
        "    # Save SHAP force plot (matplotlib fallback)\n",
        "    out_force = os.path.join(OUTPUT_DIR, f\"case_{i+1}_shap_force.png\")\n",
        "    try:\n",
        "        # shap.plots.force for JS requires notebook, so use matplotlib fallback\n",
        "        safe_shap_force_plot(explainer, explainer.shap_values(row_df), row_df, out_force)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # LIME explanation\n",
        "    lime_exp = lime_explainer.explain_instance(\n",
        "        data_row=row.values,\n",
        "        predict_fn=best_model.predict_proba,\n",
        "        num_features=min(10, len(features))\n",
        "    )\n",
        "    lime_list = lime_exp.as_list()\n",
        "    lime_html = lime_exp.as_html()\n",
        "    with open(os.path.join(OUTPUT_DIR, f\"case_{i+1}_lime.html\"), \"w\", encoding=\"utf8\") as f:\n",
        "        f.write(lime_html)\n",
        "\n",
        "    # Save textual transcription combining SHAP and LIME\n",
        "    lines = []\n",
        "    lines.append(f\"Case {i+1} index: {idx}\")\n",
        "    lines.append(f\"Predicted class: {'rejected' if pred==1 else 'accepted'}\")\n",
        "    lines.append(f\"Predicted probability of rejection: {proba:.4f}\")\n",
        "    lines.append(\"\\nTop SHAP contributions (sorted by absolute value):\")\n",
        "    for _, r in shap_contrib_df.head(6).iterrows():\n",
        "        lines.append(f\" - {r['feature']}: value={r['value']}, shap_value={r['shap_value']:.4f}\")\n",
        "    lines.append(\"\\nLIME local explanation top features:\")\n",
        "    for feat, val in lime_list:\n",
        "        lines.append(f\" - {feat}\")\n",
        "    transcription_text = \"\\n\".join(lines)\n",
        "    save_text(transcription_text, os.path.join(OUTPUT_DIR, f\"case_{i+1}_transcription.txt\"))\n",
        "\n",
        "    local_summaries.append({\n",
        "        \"case\": i+1,\n",
        "        \"index\": int(idx),\n",
        "        \"pred\": int(pred),\n",
        "        \"proba_reject\": float(proba),\n",
        "        \"top_shap\": shap_contrib_df.head(6).to_dict(orient=\"records\"),\n",
        "        \"lime\": lime_list\n",
        "    })\n",
        "\n",
        "# Save local summaries json\n",
        "save_json(local_summaries, os.path.join(OUTPUT_DIR, \"local_explanations_summary.json\"))\n",
        "\n",
        "# ===========\n",
        "# 10. Comparative analysis text between SHAP and LIME for this task\n",
        "# ===========\n",
        "comparative_text = []\n",
        "comparative_text.append(\"Comparative analysis: SHAP versus LIME for credit risk application\")\n",
        "comparative_text.append(\"\")\n",
        "comparative_text.append(\"SHAP summary\")\n",
        "comparative_text.append(\" - SHAP provides consistent additive feature attributions.\")\n",
        "comparative_text.append(\" - SHAP is useful for global and local interpretation.\")\n",
        "comparative_text.append(\" - SHAP values are stable when using the same model and data.\")\n",
        "comparative_text.append(\"\")\n",
        "comparative_text.append(\"LIME summary\")\n",
        "comparative_text.append(\" - LIME gives intuitive local linear explanations around a prediction.\")\n",
        "comparative_text.append(\" - LIME can be less stable across different perturbation seeds.\")\n",
        "comparative_text.append(\" - LIME requires careful choice of kernel and perturbation settings.\")\n",
        "comparative_text.append(\"\")\n",
        "comparative_text.append(\"Strengths and weaknesses for this credit risk task\")\n",
        "comparative_text.append(\" - SHAP is preferred for regulatory justification because it gives a consistent global story and per instance additive contributions.\")\n",
        "comparative_text.append(\" - LIME can be useful in operations to present a simple, short explanation to non technical users but should be used with caution because of stability issues.\")\n",
        "comparative_text.append(\" - Using both methods together gives complementary evidence: SHAP for robust ranking and LIME for short local narrative.\")\n",
        "comparative_text.append(\"\")\n",
        "comparative_text.append(\"Suggested usage\")\n",
        "comparative_text.append(\" - Use SHAP for model validation, feature selection, and reporting top drivers.\")\n",
        "comparative_text.append(\" - Use LIME when a short, human friendly explanation must be shown to a loan officer, with the caveat that repeated runs can vary.\")\n",
        "save_text(\"\\n\".join(comparative_text), os.path.join(OUTPUT_DIR, \"comparative_shap_vs_lime.txt\"))\n",
        "\n",
        "# ===========\n",
        "# 11. Executive summary one page plain text\n",
        "# ===========\n",
        "top3 = global_shap_importance.head(3)\n",
        "exec_lines = []\n",
        "exec_lines.append(\"Executive summary\")\n",
        "exec_lines.append(\"\")\n",
        "exec_lines.append(\"Project objective\")\n",
        "exec_lines.append(\" - Build an interpretable classifier for loan default risk with global and local explanations.\")\n",
        "exec_lines.append(\"\")\n",
        "exec_lines.append(\"Model performance on held out test set\")\n",
        "exec_lines.append(f\" - Area under ROC curve (AUC): {metrics['roc_auc']:.4f}\")\n",
        "exec_lines.append(f\" - Accuracy: {metrics['accuracy']:.4f}\")\n",
        "exec_lines.append(f\" - Precision: {metrics['precision']:.4f}\")\n",
        "exec_lines.append(f\" - Recall: {metrics['recall']:.4f}\")\n",
        "exec_lines.append(\"\")\n",
        "exec_lines.append(\"Top three global drivers of rejection risk (from SHAP mean absolute values):\")\n",
        "for _, row in top3.iterrows():\n",
        "    exec_lines.append(f\" - {row['feature']}: mean absolute SHAP = {row['mean_abs_shap']:.4f}\")\n",
        "exec_lines.append(\"\")\n",
        "exec_lines.append(\"Key recommendations\")\n",
        "exec_lines.append(\" - Investigate and mitigate the top features driving rejection risk.\")\n",
        "exec_lines.append(\" - Consider collecting higher quality data for the features with highest importance.\")\n",
        "exec_lines.append(\" - For operational explanations, present LIME style summaries to loan officers supplemented by SHAP global evidence for regulatory reports.\")\n",
        "exec_lines.append(\"\")\n",
        "exec_lines.append(\"Files produced\")\n",
        "exec_lines.append(\" - test_metrics.json: test evaluation metrics\")\n",
        "exec_lines.append(\" - global_feature_importance.csv: global feature ranking\")\n",
        "exec_lines.append(\" - case_*_transcription.txt: local explanation transcriptions\")\n",
        "exec_lines.append(\" - case_*_lime.html: LIME interactive html explanations\")\n",
        "exec_lines.append(\" - shap_summary.png: SHAP summary visualization\")\n",
        "save_text(\"\\n\".join(exec_lines), os.path.join(OUTPUT_DIR, \"executive_summary.txt\"))\n",
        "\n",
        "# ===========\n",
        "# 12. Final README of outputs mapping to rubric\n",
        "# ===========\n",
        "mapping_lines = []\n",
        "mapping_lines.append(\"Deliverables mapping to the rubric\")\n",
        "mapping_lines.append(\"\")\n",
        "mapping_lines.append(\"Task 1: Model development and tuning\")\n",
        "mapping_lines.append(\" - Provided: xgb_model.joblib and tuning_results.json and cv_train_folds.json\")\n",
        "mapping_lines.append(\"\")\n",
        "mapping_lines.append(\"Task 2: Global feature importance visualizations and interpretations\")\n",
        "mapping_lines.append(\" - Provided: xgb_feature_importance.png and shap_summary.png and global_feature_importance.csv\")\n",
        "mapping_lines.append(\"\")\n",
        "mapping_lines.append(\"Task 3: Local explanations for 5 case studies\")\n",
        "mapping_lines.append(\" - Provided: case_1..case_5_transcription.txt and case_1..case_5_shap_contributions.csv and case_1..case_5_lime.html\")\n",
        "mapping_lines.append(\"\")\n",
        "mapping_lines.append(\"Task 4: Comparative analysis of SHAP vs LIME\")\n",
        "mapping_lines.append(\" - Provided: comparative_shap_vs_lime.txt\")\n",
        "mapping_lines.append(\"\")\n",
        "mapping_lines.append(\"Task 5: Executive summary text\")\n",
        "mapping_lines.append(\" - Provided: executive_summary.txt\")\n",
        "save_text(\"\\n\".join(mapping_lines), os.path.join(OUTPUT_DIR, \"deliverables_mapping.txt\"))\n",
        "\n",
        "print(\"All outputs saved to\", OUTPUT_DIR)\n",
        "print(\"Contents:\", os.listdir(OUTPUT_DIR))\n",
        "print(\"Script finished at\", datetime.now().isoformat())"
      ]
    }
  ]
}